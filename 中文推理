python3 prepare_mel_data.py -p config/pretrain/AISHELL3/preprocess.yaml -m config/pretrain/model.yaml -t config/pretrain/train.yaml

python mel2speech.py -p config/AISHELL3/preprocess.yaml -m config/pretrain/model.yaml

python synthesize.py --text "看着跟快死了似的。" --speaker_id 166 --restore_step 100000 --reference_audio ref_audio/multiple/AISHELL3/1SSB16240032.wav --mode single -p config/AISHELL3/preprocess.yaml -m config/pretrain/model.yaml -t config/pretrain/train.yaml

python synthesize.py --text "预计将在今年的九月份在北美发售。" --speaker_id 49 --restore_step 500000 --reference_audio ref_audio/AI0935_001.wav
python synthesize.py --text "由于特斯拉拥有五十二公里的超长续航家用充电桩，可以解决用户百分之九十九的用电需求。" --speaker_id 67 --restore_step 500000 --reference_audio ref_audio/AI0935_002.wav
python synthesize.py --text "听音乐，如果没有你。" --speaker_id 176 --restore_step 500000 --reference_audio ref_audio/AI1448_001.wav

这里有一点不是很理解，predictied phoneme-level Vectors这个模块是如何训练的呢？
原文实验设置中有写: 先训练除了phoneme-level acoustic predictor的所有模块60k steps，
然后再加上predictor一起训40k steps。即先保证phoneme-level encoder的输出有表示意义
后再作为label（并且把这里的梯度截断了避免predictor影响phoneme-level acoustic encoder）

pip install torch==1.12.1+cu116 torchvision==0.13.1+cu116 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu116

python finetune.py --pretrain_dir "output/ckpt/AISHELL3/340000.pth.tar" -p config/AISHELL3/finetune.yaml -m config/newfinetune/model.yaml -t config/newfinetune/train.yaml  --vocoder_checkpoint "vocoder/generator_universal.pth.tar" --vocoder_config "vocoder/config/config_v1.json"

python synthesize_lj.py --text "He was followed by three kings whose reigns were short," --restore_step 600 --reference_audio ref_audio/LJ028-0181.wav --mode single -p config/LJSpeech/preprocess.yaml -m config/LJSpeech/model.yaml -t config/LJSpeech/train.yaml
python synthesize_lj.py --text "He says,on the day of execution there is no service in the chapel of Newgate." --restore_step 600 --reference_audio ref_audio/LJ010-0295.wav --mode single -p config/LJSpeech/preprocess.yaml -m config/LJSpeech/model.yaml -t config/LJSpeech/train.yaml

multiple:
普通话：
python synthesize.py --source sentences-ai.txt --restore_step 500000 --reference_audio ref_audio/multiple/AISHELL3/ --mode multiple -p config/AISHELL3/preprocess.yaml -m config/pretrain/model.yaml -t config/pretrain/train.yaml
英语：
python synthesize_lj.py --source sentences-lj.txt --restore_step 40000 --reference_audio ref_audio/multiple/LJSpeech/ --mode multiple -p config/LJSpeech/preprocess.yaml -m config/LJSpeech/model.yaml -t config/LJSpeech/train.yaml

